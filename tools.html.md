# tools


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

------------------------------------------------------------------------

<a href="https://github.com/numb3r33/rlm/blob/main/rlm/tools.py#L23"
target="_blank" style="float:right; font-size:smaller">source</a>

### prep_shell

>  prep_shell (context, model='openai/openai/gpt-oss-120b', base_url=None)

\*Prepare a REPL shell environment for RLM with context and recursive
LLM query capability.

Args: context: The text/data to be analyzed (stored as a variable in the
shell) model: Model name (OpenAI-compatible) base_url: API base URL for
your LLM gateway

Returns: IPython shell instance with `context` and `llm_query()`
available\*

------------------------------------------------------------------------

<a href="https://github.com/numb3r33/rlm/blob/main/rlm/tools.py#L49"
target="_blank" style="float:right; font-size:smaller">source</a>

### make_run_repl

>  make_run_repl (sh, max_output=5000)

\*Create a run_repl tool function that executes Python code in the given
shell.

Args: sh: IPython shell instance (from prep_shell) max_output: Maximum
characters to return from output (default: 5000)

Returns: Function that executes code and returns output (truncated to
max_output chars)\*
